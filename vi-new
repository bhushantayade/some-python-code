my_dict = {'a': 1, 'b': 2, 'c': 3}
key_mapping = {'a': 'alpha', 'b': 'beta'}  # Old to new keys

# Use a dictionary comprehension
my_dict = {key_mapping.get(k, k): v for k, v in my_dict.items()}

print(my_dict)


my_dict = {'a': 1, 'b': 2, 'c': 3}

# Replace key 'b' with 'new_key'
old_key = 'b'
new_key = 'new_key'

if old_key in my_dict:
    my_dict[new_key] = my_dict.pop(old_key)

print(my_dict)


my_dict = {'a': 1, 'b': 2, 'c': 3}
new_dict = {k: v for k, v in my_dict.items() if v != 2}
print(new_dict)


CREATE OR REPLACE VIEW `project.dataset.daily_file_counts` AS
WITH
  incoming AS (
    SELECT
      DATE(received_timestamp) AS file_date,
      COUNT(*) AS incoming_count
    FROM
      `project.dataset.incoming_files`
    GROUP BY
      file_date
  ),
  processed AS (
    SELECT
      DATE(processed_timestamp) AS file_date,
      COUNT(*) AS processed_count
    FROM
      `project.dataset.processed_files`
    GROUP BY
      file_date
  ),
  status AS (
    SELECT
      DATE(status_timestamp) AS file_date,
      COUNT(*) AS status_count
    FROM
      `project.dataset.file_status`
    GROUP BY
      file_date
  )
SELECT
  incoming.file_date AS date,
  IFNULL(incoming.incoming_count, 0) AS files_received,
  IFNULL(processed.processed_count, 0) AS files_processed,
  IFNULL(status.status_count, 0) AS files_logged
FROM
  incoming
FULL OUTER JOIN
  processed
ON
  incoming.file_date = processed.file_date
FULL OUTER JOIN
  status
ON
  incoming.file_date = status.file_date
ORDER BY
  date;


######
CREATE OR REPLACE VIEW `project.dataset.extracted_json_view` AS
WITH parsed_data AS (
  SELECT 
    file_id, 
    key_name,
    JSON_EXTRACT(json_string, FORMAT('$.%s', key_name)) AS json_data
  FROM 
    `project.dataset.your_table`, 
    UNNEST(JSON_EXTRACT_KEYS(json_string)) AS key_name
),
flattened_data AS (
  SELECT
    file_id,
    key_name,
    JSON_EXTRACT_SCALAR(entry, '$.key') AS key,
    CAST(JSON_EXTRACT_SCALAR(entry, '$.value') AS INT64) AS value
  FROM 
    parsed_data, 
    UNNEST(JSON_EXTRACT_ARRAY(json_data)) AS entry
)
SELECT
  file_id,
  "key" AS attribute,
  key AS attribute_value
FROM
  flattened_data
UNION ALL
SELECT
  file_id,
  "value" AS attribute,
  CAST(value AS STRING) AS attribute_value
FROM
  flattened_data;


Examples of Using JSON_EXTRACT in the WHERE Clause
1. Filtering String Values

If you have a table project.dataset.your_table with a column json_string like this:

{
  "key": "Hello World",
  "value": 123
}
Query: Filter where the key equals "Hello World":

SELECT *
FROM `project.dataset.your_table`
WHERE JSON_EXTRACT_SCALAR(json_string, '$.key') = 'Hello World';
2. Filtering Numeric Values

If you want to filter where the value is greater than 100:

SELECT *
FROM `project.dataset.your_table`
WHERE CAST(JSON_EXTRACT(json_string, '$.value') AS INT64) > 100;
3. Using JSON_EXTRACT for Nested Filtering

If the JSON is more complex, like:

{
  "details": {
    "status": "processed",
    "count": 10
  }
}
Query: Filter where status = "processed" and count > 5:

SELECT *
FROM `project.dataset.your_table`
WHERE JSON_EXTRACT_SCALAR(json_string, '$.details.status') = 'processed'
AND CAST(JSON_EXTRACT(json_string, '$.details.count') AS INT64) > 5;
4. Filtering with Arrays

If the JSON contains an array:

{
  "items": [
    {"name": "item1", "price": 50},
    {"name": "item2", "price": 100}
  ]
}
Query: Filter where any item's price is greater than 80:

SELECT *
FROM `project.dataset.your_table`
WHERE EXISTS (
  SELECT 1 
  FROM UNNEST(JSON_EXTRACT_ARRAY(json_string, '$.items')) AS item
  WHERE CAST(JSON_EXTRACT_SCALAR(item, '$.price') AS INT64) > 80
);
Best Practices:
Use JSON_EXTRACT_SCALAR when working with simple string comparisons to avoid extra parsing.
Cast Values if you are comparing numeric fields.
Use EXISTS or UNNEST when working with arrays.

SELECT
  file_id,
  key_name,
  JSON_EXTRACT(json_string, FORMAT('$.%s', key_name)) AS extracted_data
FROM
  `project.dataset.json_table`, 
  UNNEST(JSON_EXTRACT_KEYS(json_string)) AS key_name
WHERE
  key_name LIKE 'aw3%';


#######
WITH parsed_data AS (
  SELECT
    file_id,
    key_name,
    JSON_EXTRACT(json_string, FORMAT('$.%s', key_name)) AS extracted_data
  FROM
    `project.dataset.json_table`,
    UNNEST(REGEXP_EXTRACT_ALL(json_string, r'"([^"]+)":')) AS key_name
)
SELECT 
  file_id,
  key_name,
  extracted_data
FROM 
  parsed_data
WHERE 
  key_name LIKE 'aw3%';

####

import re

# Sample dictionary
data = {
    "aw34asdada": [{"key": "Hello World", "value": 123}],
    "bhusedada": [{"st_date": "12-12-2020", "ed": 123}],
    "aw56something": [{"key": "Test Key", "value": 456}]
}

# Find keys that match the pattern (like 'aw3%')
pattern = re.compile(r'^aw3')

# Append a value to matching keys
new_entry = {"key": "New Entry", "value": 999}

for key in data.keys():
    if pattern.match(key):
        data[key].append(new_entry)

# Print updated dictionary
print(data)

### new code
WITH parsed_data AS (
  SELECT
    file_id,
    key_name,
    JSON_QUERY(json_string, CONCAT('$.', key_name)) AS extracted_data
  FROM
    `project.dataset.json_table`,
    UNNEST(REGEXP_EXTRACT_ALL(json_string, r'"([^"]+)":')) AS key_name
)
SELECT 
  file_id,
  key_name,
  extracted_data
FROM 
  parsed_data
WHERE 
  key_name LIKE 'aw3%' 
  AND extracted_data IS NOT NULL;

## one more approch

WITH parsed_data AS (
  SELECT
    file_id,
    key_name,
    JSON_VALUE(json_string, CONCAT('$.', key_name)) AS extracted_data
  FROM
    `project.dataset.json_table`,
    UNNEST(REGEXP_EXTRACT_ALL(json_string, r'"([^"]+)":')) AS key_name
)
SELECT 
  file_id,
  key_name,
  extracted_data
FROM 
  parsed_data
WHERE 
  key_name LIKE 'aw3%' 
  AND extracted_data IS NOT NULL;
