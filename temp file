import re

# Adjusted pattern to allow hyphens in bucket and folder names
pattern = r'(?P<bucket>[\w\-]+)_(?P<folder>[\w\-]+)_(?P<start_time>\d{8}T\d{4})_(?P<end_time>\d{8}T\d{4})_v(?P<version>\d+)_(?P<file_name>[\w\-]+)\.(?P<extension>\w+)'

file1 = 'gcs-bucket-1_folder-A_20230901T1200_20230901T1300_v1_file1.csv'
file2 = 'gcs-bucket-2_folder-B_20230901T1200_20230901T1300_v1_file2.json'

# Match the pattern with the filenames
match1 = re.match(pattern, file1)
match2 = re.match(pattern, file2)

if match1 and match2:
    # Extract matched components as dictionaries
    components1 = match1.groupdict()
    components2 = match2.groupdict()

    # Compare components (e.g., start and end times)
    if components1['start_time'] == components2['start_time'] and components1['end_time'] == components2['end_time']:
        print("The start and end times match!")
    else:
        print("The start and end times do not match.")
else:
    print("Pattern did not match the file names.")





import re

def validate_filename(filename):
    # Define the pattern
    pattern = r'^(?P<filename>\w+)_(?P<starttime>\d{8}_\d{6})_(?P<endtime>\d{8}_\d{6})_(?P<bucketname>\w+)\.(?P<extension>\w+)$'
    
    # Match the filename with the pattern
    match = re.match(pattern, filename)
    
    if match:
        # Extract the groups if needed
        file_details = match.groupdict()
        return True, file_details
    else:
        return False, None

# Test cases
test_filename = "logfile_20240908_120000_20240908_130000_mybucket.txt"
is_valid, details = validate_filename(test_filename)

if is_valid:
    print("Valid file name:", details)
else:
    print("Invalid file name")




import csv
import pandas as pd

def infer_data_type(value):
    """Infer data type of a value."""
    try:
        int(value)
        return "int"
    except ValueError:
        try:
            float(value)
            return "float"
        except ValueError:
            try:
                pd.to_datetime(value)
                return "date"
            except ValueError:
                return "str"

def generate_schema_from_csv(csv_file_path):
    """Generate schema from the CSV file by reading the first row of data."""
    schema = {}
    
    with open(csv_file_path, mode='r') as file:
        reader = csv.DictReader(file)
        first_row = next(reader)  # Read the first row of data
        
        for column, value in first_row.items():
            schema[column] = infer_data_type(value)
    
    return schema

def validate_schema(generated_schema, existing_schema):
    """Compare the generated schema with the existing schema."""
    for column, data_type in existing_schema.items():
        if column not in generated_schema:
            print(f"Missing column: {column}")
        elif generated_schema[column] != data_type:
            print(f"Mismatch in column '{column}': Expected {data_type}, got {generated_schema[column]}")
        else:
            print(f"Column '{column}' matches the expected schema.")
    
    for column in generated_schema:
        if column not in existing_schema:
            print(f"Unexpected column in CSV: {column}")

# Path to CSV file
csv_file_path = "sample_data.csv"

# Generate schema from CSV
generated_schema = generate_schema_from_csv(csv_file_path)

# Validate generated schema with existing schema
validate_schema(generated_schema, existing_schema)



######
WITH date_series AS (
    -- Generate a series of dates (adjust range as needed)
    SELECT actual_date
    FROM UNNEST(GENERATE_DATE_ARRAY(CURRENT_DATE, CURRENT_DATE + INTERVAL 30 DAY)) AS actual_date
),
hour_series AS (
    -- Generate hours (0 to 23)
    SELECT hour AS actual_hour
    FROM UNNEST(GENERATE_ARRAY(0, 23)) AS hour
),
minute_series AS (
    -- Generate 10-minute intervals (0, 10, ..., 50)
    SELECT minute AS actual_minute
    FROM UNNEST(GENERATE_ARRAY(0, 50, 10)) AS minute
)
SELECT
    mt.file_name,
    mt.file_name_pattern,
    CASE
        WHEN mt.file_name = 'file1' THEN 
            FORMAT('%s_%s', mt.file_name, FORMAT_DATE('%Y%m%d', ds.actual_date))
        WHEN mt.file_name = 'file2' THEN 
            FORMAT('%s_%s_%02d', mt.file_name, FORMAT_DATE('%Y%m%d', ds.actual_date), hs.actual_hour)
        WHEN mt.file_name = 'file3' THEN 
            FORMAT('%s_%s_%02d_%02d', mt.file_name, FORMAT_DATE('%Y%m%d', ds.actual_date), hs.actual_hour, ms.actual_minute)
    END AS expanded_file_name
FROM master_table mt
CROSS JOIN date_series ds
LEFT JOIN hour_series hs ON mt.file_name IN ('file2', 'file3') -- Restrict hours for file2 and file3
LEFT JOIN minute_series ms ON mt.file_name = 'file3'; -- Restrict minutes only for file3

#####
WITH RECURSIVE date_series AS (
    -- Generate a series of dates (adjust range as needed)
    SELECT 
        CURRENT_DATE AS actual_date
    UNION ALL
    SELECT 
        actual_date + INTERVAL 1 DAY
    FROM date_series
    WHERE actual_date < CURRENT_DATE + INTERVAL 30 DAY -- Change this for a larger range
),
hour_series AS (
    -- Generate hours (0 to 23)
    SELECT 
        hour AS actual_hour
    FROM UNNEST(GENERATE_ARRAY(0, 23)) AS hour
),
minute_series AS (
    -- Generate 10-minute intervals (0, 10, ..., 50)
    SELECT 
        minute AS actual_minute
    FROM UNNEST(GENERATE_ARRAY(0, 50, 10)) AS minute
)
SELECT
    mt.file_name,
    mt.file_name_pattern,
    CASE
        WHEN mt.file_name = 'file1' THEN 
            FORMAT('%s_%s', mt.file_name, FORMAT_DATE('%Y%m%d', ds.actual_date))
        WHEN mt.file_name = 'file2' THEN 
            FORMAT('%s_%s_%02d', mt.file_name, FORMAT_DATE('%Y%m%d', ds.actual_date), hs.actual_hour)
        WHEN mt.file_name = 'file3' THEN 
            FORMAT('%s_%s_%02d_%02d', mt.file_name, FORMAT_DATE('%Y%m%d', ds.actual_date), hs.actual_hour, ms.actual_minute)
    END AS expanded_file_name
FROM master_table mt
CROSS JOIN date_series ds
LEFT JOIN hour_series hs ON mt.file_name IN ('file2', 'file3')
LEFT JOIN minute_series ms ON mt.file_name = 'file3';



